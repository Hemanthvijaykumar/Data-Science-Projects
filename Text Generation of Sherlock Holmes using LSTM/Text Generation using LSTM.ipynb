{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Activation\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 561833\n"
     ]
    }
   ],
   "source": [
    "with open('./dataset/sherlock_holmes.txt', 'r') as file:\n",
    "    text = file.read().lower()\n",
    "print('text length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars 55\n"
     ]
    }
   ],
   "source": [
    "#get all the unique characters in the text\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5, '(': 6, ')': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, 'a': 25, 'b': 26, 'c': 27, 'd': 28, 'e': 29, 'f': 30, 'g': 31, 'h': 32, 'i': 33, 'j': 34, 'k': 35, 'l': 36, 'm': 37, 'n': 38, 'o': 39, 'p': 40, 'q': 41, 'r': 42, 's': 43, 't': 44, 'u': 45, 'v': 46, 'w': 47, 'x': 48, 'y': 49, 'z': 50, 'à': 51, 'â': 52, 'è': 53, 'é': 54}\n"
     ]
    }
   ],
   "source": [
    "#build character indices\n",
    "char_indices = dict((c,i) for i,c in enumerate(chars))\n",
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '&', 5: \"'\", 6: '(', 7: ')', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '?', 25: 'a', 26: 'b', 27: 'c', 28: 'd', 29: 'e', 30: 'f', 31: 'g', 32: 'h', 33: 'i', 34: 'j', 35: 'k', 36: 'l', 37: 'm', 38: 'n', 39: 'o', 40: 'p', 41: 'q', 42: 'r', 43: 's', 44: 't', 45: 'u', 46: 'v', 47: 'w', 48: 'x', 49: 'y', 50: 'z', 51: 'à', 52: 'â', 53: 'è', 54: 'é'}\n"
     ]
    }
   ],
   "source": [
    "#build indices_char\n",
    "indices_char = dict((i,c) for i,c in enumerate(chars))\n",
    "print(indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get valuable data,which we can use to train our model, we will split our data up into subsequences with a length of 40 characters. Then we will transform our data to an boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text)-maxlen, step):\n",
    "    sentences.append(text[i: i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187265\n",
      "187265\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(len(next_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create x\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187265, 40, 55)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187265, 55)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create y\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import other libraries\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape = (maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions from keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback, ModelCheckpoint, ReduceLROnPlateau\n",
    "import sys\n",
    "import io\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other checkpoints\n",
    "filepath = r\"D:\\\\Backup_of_exact_MY_REPO\\\\model Weights\\\\weights_text_generation.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                             verbose=1, save_best_only=True,\n",
    "                             mode='min')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                              patience=1, min_lr=0.001)\n",
    "\n",
    "callbacks = [print_callback, checkpoint, reduce_lr]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "187265/187265 [==============================] - 125s 668us/step - loss: 1.5299\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e and some very\n",
      "bulky boxes driving rapi\"\n",
      "e and some very\n",
      "bulky boxes driving raping the contrary and a state of the paper when i was a man when i shall be and some condined and a morning of the concers of the discreced to the company with a colone of the colone of the concert that i am a little the track and the matter and some and was a little the contrary of the colone of the strange of the comple and we had a colone of the contrary to the concertion with a contrary of the c\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e and some very\n",
      "bulky boxes driving rapi\"\n",
      "e and some very\n",
      "bulky boxes driving raping my convince and came a monol, and we have a more really and little him that the right to be a police was in\n",
      "the corner and the little the front of a bridely and was wall to the proves a little bener of a strengt than i coild a discrock down in a givened and stood little dight of a strange to the corder and scone of the compleed the stipped at astlught in the little at the comonnt, which was a c\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e and some very\n",
      "bulky boxes driving rapi\"\n",
      "e and some very\n",
      "bulky boxes driving rapin to the muins, who is all, he had littre hore preal was little bether he me\n",
      "blki viollock was\n",
      "is a vervitid the\n",
      "alr of cur the brid,\" said i, must convinced front to know without sigrllant. i don't know sharttatten. \"butfind then? yed is eyough your shend to\n",
      "the dusconed of the rood. \"the ode at over this a light' treat a pical and leitt a lingured, you'n in trial clasone mauntion. i doent the cl\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e and some very\n",
      "bulky boxes driving rapi\"\n",
      "e and some very\n",
      "bulky boxes driving raping no, and upon oven\n",
      "can\n",
      "caperi'm at,\n",
      "and\n",
      "have\n",
      "come igh\n",
      "wass puch\n",
      "forwartyon. did you quine mabler little digb ot to delone of that\n",
      "his lin to lerfair you.\n",
      "then' oflces, with\n",
      "the\n",
      "clamp\n",
      "at little glisted walsed in the hwarved i\n",
      "afterulled of a raced of\n",
      "arstacked colden my blooch; und the readed of pace,'\n",
      "and crotfisain of loy wityed of your\n",
      "chole to\n",
      "rrif we hover.\" ageon.\"\n",
      "\n",
      "\"you weatee to he moss i\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.52991, saving model to D:\\\\Backup_of_exact_MY_REPO\\\\model Weights\\\\weights_text_generation.hdf5\n",
      "Epoch 2/5\n",
      "187265/187265 [==============================] - 131s 700us/step - loss: 1.4590\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"gates, and we heard\n",
      "the hoarse roar of t\"\n",
      "gates, and we heard\n",
      "the hoarse roar of the state of the state of the singular and sound that i asked to me to the stated to me to see the matter and start of the most of the concensed to the wey in the concensed that i have been the most and side to see this confing of the concensed that i was a street in the state of the state of the concensed to the stated to the possible that the concension of the inster the concensed to the matter t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"gates, and we heard\n",
      "the hoarse roar of t\"\n",
      "gates, and we heard\n",
      "the hoarse roar of the situable light from the side at the condinate of the sumbers to this confing and hand must as has incaned that\n",
      "the street with a very seen to the matter to my pensted to the man was\n",
      "beact confideran in at myself and langed the natural that the centre has not a most that the good man was before this begund to the window when you have an into the roan of the window the recorder with the means whi\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"gates, and we heard\n",
      "the hoarse roar of t\"\n",
      "gates, and we heard\n",
      "the hoarse roar of that by a surning and\n",
      "foothand.\n",
      "\n",
      "\"which you said the some\n",
      "exactip has matter though,\n",
      "behand-showly round one bacajingly, and\n",
      "mr. uinttauge of nightibl of\n",
      "one importuries, 'i have been hourished as he\n",
      "three what end that\n",
      "white to my\n",
      "bolity dit's maze gatuin. bogld. eyes\n",
      "aistet\n",
      "her could to\n",
      "the sugge-stread caims of before linging so gig-laid mornob was outlnse thingal reall by gardly do,' sair holde\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"gates, and we heard\n",
      "the hoarse roar of t\"\n",
      "gates, and we heard\n",
      "the hoarse roar of them.\n",
      "\n",
      "a puirt stilk, but i had bean perand\n",
      "you\n",
      "me?\"\n",
      "\n",
      "\"the pate a\n",
      "fibl vent led someing?\"\n",
      "\n",
      "\"i clooked usened !\"wer, so bellain.\n",
      "unded that the wilfoge at my\n",
      "hine of any,' dhon tark bram\" upon? the\n",
      "cerraicaim dit painemingly gear the small so nytimatold inctar.\n",
      "but in the fourd. \"he; ence?\n",
      "ne than; but i  and own\n",
      "kourdleed an outsiby deterpe.' he oblection of brown\n",
      "and little smull.\"\n",
      "\n",
      "\"'the meatumes\n",
      "\n",
      "Epoch 00002: loss improved from 1.52991 to 1.45896, saving model to D:\\\\Backup_of_exact_MY_REPO\\\\model Weights\\\\weights_text_generation.hdf5\n",
      "Epoch 3/5\n",
      "187265/187265 [==============================] - 130s 693us/step - loss: 1.4122\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"rch, and then leaving me? now, if he had\"\n",
      "rch, and then leaving me? now, if he had been a singular of the confider and the confire of the confider and the confider and the start and so see that the confiderably side of the confiders in the door which i have no compliment any long be to the police and made a surp the man which i have no compenters and the singular and the start of the matter and man who had been a singular and the stands which i have no dear the strange than the\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rch, and then leaving me? now, if he had\"\n",
      "rch, and then leaving me? now, if he had been a truat, which i do nother anything for the look upon the other any good between any hand, and i have deturned at the down to the late to soff.\n",
      "\n",
      "\"'but they has been problement a singular and to down the window. it was the case worded you the confire of the start and large of a promomber in a very character and the problem in a freat anything out in the come, and i could see that the country \n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"rch, and then leaving me? now, if he had\"\n",
      "rch, and then leaving me? now, if he hadds a bloo?\"\n",
      "\n",
      "\"no, when?\"\n",
      "\n",
      "\"yes, a case was now you before?\"\n",
      "\n",
      "\"oh, and so vary see a since shat course by his o'col prever to be,\n",
      "not never\n",
      "brienon, but there is\n",
      "wohat and money saveryperfer company\n",
      "pirabing where we wared ant our violen croto under the fird, and we you just to the, but the\n",
      "glance. that what is very never breaking\n",
      "in him.\n",
      "she will be eviduce yourshing upon my pill. my han forever a\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"rch, and then leaving me? now, if he had\"\n",
      "rch, and then leaving me? now, if he had a ging brauted and or gurmating. she could dr. n'ther gloobs when,\" said the pointar you. i hanton down into knew do any awoodhing. theresmur of the end for goese quite down all, which he marria, any rodgelp by tink that your\n",
      "head anytered beft their\n",
      "five roam was search the perclidate firning, o'ple.\"\n",
      "\n",
      "he was eyed what are it intenedry was\n",
      "wall axife rearing that remarkless at one\n",
      "to threp, but \n",
      "\n",
      "Epoch 00003: loss improved from 1.45896 to 1.41217, saving model to D:\\\\Backup_of_exact_MY_REPO\\\\model Weights\\\\weights_text_generation.hdf5\n",
      "Epoch 4/5\n",
      "187265/187265 [==============================] - 123s 659us/step - loss: 1.3791\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" but it was dreadful hard before\n",
      "his mot\"\n",
      " but it was dreadful hard before\n",
      "his motion of the last that i had a surprised to the street. i shall be a strong of the strong of the door in the street to the street. i had a surprised to the street to the morning and the side, and the street to the table to the man of the man who had been a strange in the man who had been the singular and i am sure it is a strange than the strong of the man who had been the street and the street. i h\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" but it was dreadful hard before\n",
      "his mot\"\n",
      " but it was dreadful hard before\n",
      "his motidred had a see, i had the man was the cloting and in the corner of my lawn, and the drove in the man who have to know that i have been the one of the deseright down to the street.\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"you have no tell to my side, i shall cas eyes and in a smophing to the ready to the face, he was in the red to the exise in the house of the really could was absolutely andress in the house, and the lowed in the stro\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \" but it was dreadful hard before\n",
      "his mot\"\n",
      " but it was dreadful hard before\n",
      "his motheled his\n",
      "wood-do\n",
      "dilctomed then waiting over. yours inever, sill i am i det imaninal.\"\n",
      "\n",
      "\"little knew the manal, shows, that i realle, and that we shall gee teast destranger, and he would not given where hud.'\n",
      "\n",
      "\"'that.\"\n",
      "\n",
      "\"in the silk,' he\n",
      "extrimed a miders, looking\n",
      "swergul in 180ow\n",
      "adouming terriffeciso finished.\n",
      "\n",
      "\"what, how crung it up in foctograg-walked i may leave, i was extertion to the\n",
      "footl\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \" but it was dreadful hard before\n",
      "his mot\"\n",
      " but it was dreadful hard before\n",
      "his moti well, only cleared, \"how fow wet!\"e\n",
      "fillodges upones.\"\n",
      "\n",
      "\"therefully.\"\n",
      "\n",
      "repalled, his\n",
      "mying least her.\"i rungular tow. was a\n",
      "peice question himmcive,\n",
      "i can cured it here, where is pooldsment mine. neyt they ungecing him.\n",
      "\n",
      "holmes.\"\n",
      "\n",
      "\"perken broued out i stopsed from weist. he has uponed\n",
      "freal it upon\n",
      "a bloods it arryded stood\n",
      "somentive his thingteffipremed why!'\n",
      "hage\n",
      "ught subutsions.\n",
      "\"you will see\n",
      "\n",
      "Epoch 00004: loss improved from 1.41217 to 1.37915, saving model to D:\\\\Backup_of_exact_MY_REPO\\\\model Weights\\\\weights_text_generation.hdf5\n",
      "Epoch 5/5\n",
      "187265/187265 [==============================] - 121s 647us/step - loss: 1.3517\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"e,\" broke in the engineer, \"is dr. beche\"\n",
      "e,\" broke in the engineer, \"is dr. bechester and the country of the country of the street of the street and much to the paper and here and the problem of the back and the problem of the partion of his chance to the street and the most and some that the street to the leave the singular and the matter that i have a suther a love that the conclime of the partion of the concliming the street and looking to the present which he was a place a\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e,\" broke in the engineer, \"is dr. beche\"\n",
      "e,\" broke in the engineer, \"is dr. bechested to the door and sitting upon my track so. i found the engenty were has in a criminal about that the sturner room, the will be at leatters of the look and little burness of the street and any luced from his caintate of the silen as he fall of the face, the police as the country, and a chair of the street in the very when i can gave a window, and he had heard the thrown the matter and the other\n",
      "----- diversity: 1.0\n",
      "----- Generating with seed: \"e,\" broke in the engineer, \"is dr. beche\"\n",
      "e,\" broke in the engineer, \"is dr. bechesaily, a chuchotion, jush bot be for me.\n",
      "\n",
      "\"'oh, i have a notub.\"\n",
      "\n",
      "\"well,\" said brought\n",
      "alever to see come pay that accioused it\n",
      "awash of his face to deserds. the very\n",
      "netoor than atition, pronable cill gloom\n",
      "i vaunt very opencessions. to aftarjest, therefore\n",
      "the couni to a ciss, and it was a clep, takp to did not an lead been has been from know where i tellest he come ong over the pich only know w\n",
      "----- diversity: 1.2\n",
      "----- Generating with seed: \"e,\" broke in the engineer, \"is dr. beche\"\n",
      "e,\" broke in the engineer, \"is dr. bechears\n",
      "depead-hall,\n",
      "a ligh swirge, tractain.\n",
      "the 0, fornive it into a\n",
      "luf his face. it wsbut out by well if you have naturned vassa\n",
      "busines-exkine of the crames was tell our hapifi'tless wite noses you not holmes\n",
      ".\n",
      "the prung to have i , sal, learnutemeghed\n",
      "indemred, any were bus a londwy\n",
      "occurted with\n",
      "his eye of\n",
      "aiche to agcosmoguinn,\"\n",
      "itr!'y know hulder, was thear lame to large plads.\n",
      "she was.\n",
      "\n",
      "\"ay,\n",
      "\n",
      "Epoch 00005: loss improved from 1.37915 to 1.35171, saving model to D:\\\\Backup_of_exact_MY_REPO\\\\model Weights\\\\weights_text_generation.hdf5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "history = model.fit(x, y, batch_size=512, epochs = 5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate text ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the helper function and slightly modify it to generate text ourselves\n",
    "def generate_text(length, diversity):\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yself clear?\"\n",
      "\n",
      "\"i am to remain neutral, and the police and the country of the street and the street and the street that the much any commitse of the street and the problem of the country of the street and the country of the country of the street and some things of the street and the country of the street of the country of the street and the sign of the concless from his chair of the country of the street and the country of the street of the street and the things and look and the considered that the country was the matter to the most a\n"
     ]
    }
   ],
   "source": [
    "#generate text by calling that function\n",
    "print(generate_text(500, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a lot of things you can improve about the model to get better outputs. A few of them are:\n",
    "\n",
    "Using a more sophisticated network structure (more LSTM-, Dense Layers),\n",
    "Training for more epochs,\n",
    "Playing around with the batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's the end of the code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
